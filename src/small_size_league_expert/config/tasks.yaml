language_detection_decomposition_task:
  description: >
    Systematically analyze the input question to detect language and decompose into strategic sub-questions that maximize retrieval effectiveness.
    
    CHAIN OF THOUGHT PROCESS:
    Step 1: Language Detection Analysis
    - Identify primary language using linguistic markers
    - Note any mixed-language elements or technical terms
    - Assign ISO language code with confidence level
    
    Step 2: Question Semantic Analysis
    - Extract core technical concepts
    - Identify question type (what/how/why/when/where)
    - Determine complexity level and target audience
    
    Step 3: Sub-Question Generation Strategy
    - Generate focused sub-questions covering different knowledge domains
    - Ensure each sub-question targets specific retrievable information
    - Validate sub-questions align with available knowledge sources
    
    FEW-SHOT EXAMPLES:
    
    Example 1:
    Input: "Â¿CuÃ¡les son las dimensiones oficiales del campo de fÃºtbol robot?"
    Language: es (Spanish)
    Sub-questions:
    1. "What are the official SSL field dimensions in meters?"
    2. "What are the goal area specifications in SSL?"
    3. "What are the penalty area measurements in SSL?"
    
    Example 2:
    Input: "How does the vision system track multiple robots simultaneously?"
    Language: en (English)
    Sub-questions:
    1. "What computer vision algorithms are used in SSL global vision?"
    2. "How does SSL vision system handle robot identification and tracking?"
    3. "What are the technical specifications of SSL vision hardware?"
    
    Example 3:
    Input: "Wie funktioniert die Kommunikation zwischen Robotern im Spiel?"
    Language: de (German)
    Sub-questions:
    1. "What communication protocols are allowed in SSL robot teams?"
    2. "How do SSL robots coordinate during gameplay?"
    3. "What are the communication frequency limitations in SSL?"
  expected_output: >
    A structured analysis containing:
    1. Detected language code (ISO format)
    2. Confidence level for language detection (1-10)
    3. Core technical concepts identified
    4. Question complexity assessment (beginner/intermediate/advanced)
    5. Exactly 3-4 focused sub-questions in English that:
       - Cover different knowledge domains (technical/rules/strategy)
       - Are directly answerable using available sources
       - Maintain semantic coherence with original question
       - Follow the few-shot examples pattern
  agent: language_decomposer

retrieval_task:
  description: >
    Execute strategic content retrieval using systematic search methodology to gather comprehensive, authoritative information for each sub-question.
    
    CHAIN OF THOUGHT PROCESS:
    Step 1: Source Prioritization Strategy
    - Analyze each sub-question to determine optimal source types
    - Prioritize MCP SSL-specific sources for domain knowledge
    - Identify Wikipedia needs for general technical concepts
    - Plan search query optimization for maximum relevance
    
    Step 2: MCP Source Exploitation
    - Execute targeted searches using SSL-specific terminology
    - Retrieve official documentation, rules, and specifications
    - Gather team descriptions and technical papers
    - Extract competition guidelines and historical data
    
    Step 3: Wikipedia Supplementation
    - Search for general technical concepts not in SSL sources
    - Retrieve foundational knowledge (algorithms, protocols, hardware)
    - Gather context for technical terms and methodologies
    - Supplement with academic and industry standards
    
    Step 4: Content Quality Assessment
    - Validate source authority and recency
    - Ensure content directly addresses sub-questions
    - Check for completeness and technical accuracy
    - Document source metadata for ranking phase
    
    SEARCH STRATEGY EXAMPLES:
    
    Technical Sub-question: "What computer vision algorithms are used in SSL global vision?"
    - MCP Search: "SSL vision system algorithms camera calibration object detection"
    - Wikipedia Search: "computer vision object tracking algorithms stereo vision"
    
    Rules Sub-question: "What are the official SSL field dimensions?"
    - MCP Search: "SSL field specifications dimensions official rules"
    - Wikipedia Search: "Not needed - domain-specific information"
    
    Strategy Sub-question: "How do teams coordinate robot formations?"
    - MCP Search: "SSL team coordination formation strategy tactical planning"
    - Wikipedia Search: "multi-agent coordination distributed systems"
  expected_output: >
    A comprehensive collection organized by sub-question containing:
    1. Retrieved content snippets with exact source URLs
    2. Source authority level (official/academic/community)
    3. Content relevance score (1-10) for each snippet
    4. Publication date or last update when available
    5. Technical depth level (basic/intermediate/advanced)
    6. Coverage completeness assessment for each sub-question
    7. Identified knowledge gaps where no suitable content was found
    
    Format: Structured list with clear source attribution and metadata for optimal ranking phase input.
  agent: retriever

ranking_task:
  description: >
    Apply systematic evaluation criteria using chain-of-thought analysis to rank and filter retrieved content for maximum educational value and accuracy.
    
    CHAIN OF THOUGHT RANKING PROCESS:
    
    Step 1: Relevance Assessment Matrix
    For each content snippet, evaluate:
    - Direct answer potential (Does it directly address the sub-question?)
    - Conceptual alignment (How well does it match the original question intent?)
    - Technical depth appropriateness (Matches user's apparent knowledge level?)
    - Scope coverage (How much of the sub-question does it answer?)
    
    Step 2: Authority and Reliability Scoring
    - Source credibility: Official SSL > Academic > Team Documentation > Community
    - Content freshness: Recent official updates > Historical documentation
    - Technical accuracy indicators: References, citations, technical detail level
    - Community validation: Known reliable sources vs unverified content
    
    Step 3: Educational Value Analysis
    - Pedagogical progression: Builds understanding systematically
    - Practical applicability: Actionable information vs theoretical only
    - Completeness: Provides sufficient detail for understanding
    - Clarity: Technical accuracy without unnecessary complexity
    
    Step 4: Synthesis Optimization
    - Complementary content identification: Pieces that work well together
    - Redundancy elimination: Remove duplicate information
    - Gap identification: Missing critical information areas
    - Answer architecture: How pieces combine for comprehensive response
    
    RANKING CRITERIA EXAMPLES:
    
    High Priority (Score 9-10):
    - Official SSL rules document excerpt answering field dimensions
    - Recent technical committee clarification on specific rule interpretation
    - Peer-reviewed algorithm description with SSL implementation details
    
    Medium Priority (Score 6-8):
    - Team description paper explaining successful strategy implementation
    - Academic paper with relevant algorithmic approach
    - Community-validated technical explanation with practical examples
    
    Low Priority (Score 3-5):
    - General Wikipedia article requiring significant context
    - Outdated documentation with superseded information
    - Incomplete explanations requiring substantial supplementation
    
    Exclude (Score 1-2):
    - Content unrelated to SSL or sub-questions
    - Contradictory information without authoritative resolution
    - Severely outdated or incorrect technical information
  expected_output: >
    A precisely ranked collection containing:
    1. Top 5-8 content snippets ranked by composite score (1-10)
    2. Detailed ranking justification for each selected snippet
    3. Authority level and source reliability assessment
    4. Educational value and pedagogical appropriateness rating
    5. Identified content gaps requiring synthesis or acknowledgment
    6. Recommended answer structure using ranked content
    7. Quality assurance notes for answer generation phase
    
    Format: Structured ranking with clear rationale enabling optimal answer synthesis.
  agent: ranker

answer_generation_task:
  description: >
    Synthesize ranked content into an engaging, pedagogically optimized Discord response that educates while maintaining technical accuracy and platform constraints.
    
    CHAIN OF THOUGHT ANSWER CONSTRUCTION:
    
    Step 1: Content Synthesis Strategy
    - Analyze ranked content for logical flow and narrative structure
    - Identify key concepts requiring definition or context
    - Plan information hierarchy from fundamental to advanced
    - Determine optimal balance between comprehensiveness and conciseness
    
    Step 2: Language and Formatting Adaptation
    - Detect target language from original question analysis
    - Plan technical term translation strategy maintaining accuracy
    - Design Discord formatting for maximum readability
    - Optimize emoji placement for engagement without compromising professionalism
    
    Step 3: Source Integration Architecture
    - Plan inline citation strategy for each factual claim
    - Ensure every technical statement has authoritative backing
    - Design reference format for translated content marking
    - Validate all links are functional and accessible
    
    Step 4: Educational Value Optimization
    - Structure content for progressive understanding
    - Include practical implications where relevant
    - Anticipate follow-up questions and address preemptively
    - Balance technical depth with accessibility
    
    RESPONSE STRUCTURE TEMPLATE:
    
    ```
    **ðŸ¤– Based on your question: "{original_question}"**
    
    ## ðŸ” [Main Concept Title]
    
    [Core explanation with inline citations]
    
    ### ðŸ“‹ Key Technical Details:
    â€¢ [Specific fact with [source](link)]
    â€¢ [Another fact with [source](link)]
    â€¢ [Additional detail with [source](link)]
    
    ### âš™ï¸ Practical Implications:
    [How this applies in real SSL contexts]
    
    ---
    *âš ï¸ This answer is AI-generated from SSL knowledge sources. Verify critical information with official SSL documentation.*
    ```
    
    FORMATTING EXAMPLES:
    
    English Response:
    "ðŸ¤– **Based on your question: "How does SSL vision work?"**
    
    ## ðŸ” SSL Global Vision System
    
    The [SSL vision system uses multiple overhead cameras](https://ssl.robocup.org/vision) to track all robots and the ball simultaneously..."
    
    Spanish Response:
    "ðŸ¤– **Basado en tu pregunta: "Â¿CÃ³mo funciona la visiÃ³n SSL?"**
    
    ## ðŸ” Sistema de VisiÃ³n Global SSL
    
    El [sistema de visiÃ³n SSL utiliza mÃºltiples cÃ¡maras aÃ©reas](https://ssl.robocup.org/vision) para rastrear todos los robots y la pelota simultÃ¡neamente..."
    
    CHARACTER LIMIT MANAGEMENT:
    - Target 1800 characters maximum (200 character buffer)
    - Prioritize most critical information first
    - Use bullet points for efficient information density
    - Implement graceful truncation with continuation indicators
  expected_output: >
    A Discord-optimized response containing:
    1. Question acknowledgment in original language
    2. Structured answer with clear sections and headers
    3. Inline source citations for every factual claim
    4. Strategic emoji usage for engagement and readability
    5. Technical accuracy with appropriate complexity level
    6. Character count under 2000 with graceful handling if exceeded
    7. Proper translation markers for non-English content
    8. Professional disclaimer and verification reminder
    9. Engaging format encouraging further learning
    
    Format: Discord Markdown with functional links, proper formatting, and educational structure optimized for SSL community engagement.
  agent: answer_generator
